{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This file contains sample code to perform the data querying of the Reddit forum r/WallStreetBets."
      ],
      "metadata": {
        "id": "w9phcfZuAnEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install praw"
      ],
      "metadata": {
        "id": "ymbUcBcxlH8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HaJ8LjwkYYj"
      },
      "outputs": [],
      "source": [
        "import praw\n",
        "from google.colab import userdata\n",
        "import time\n",
        "\n",
        "# Set up PRAW with your Reddit API credentials\n",
        "reddit = praw.Reddit(\n",
        "    client_id= userdata.get('clientID'),\n",
        "    client_secret= userdata.get('clientSecret'),\n",
        "    user_agent= userdata.get('userAgent')\n",
        ")\n",
        "\n",
        "# Specify the subreddit you want to scrape\n",
        "subreddit_name = 'WallStreetBets'\n",
        "subreddit = reddit.subreddit(subreddit_name)\n",
        "\n",
        "data = []\n",
        "\n",
        "def dataStore(postID,postTitle,postContent,votes,numComments):\n",
        "   return {'post_id': postID,\n",
        "           'post_title': postTitle,\n",
        "           'post_content': postContent,\n",
        "           'upvotes': votes,\n",
        "           'num_comments': numComments}\n",
        "\n",
        "# Iterate through the top 2000 posts in the subreddit\n",
        "for submission in subreddit.top(limit=2000):\n",
        "    # Extract relevant information\n",
        "    post_id = submission.id\n",
        "    post_title = submission.title\n",
        "    post_content = submission.selftext  # Use 'title' for post title\n",
        "    upvotes = submission.score\n",
        "    num_comments = submission.num_comments\n",
        "\n",
        "    # print(f\"Post ID: {post_id}\")\n",
        "    # print(f\"Title: {post_title}\")\n",
        "    # print(f\"Content: {post_content}\")\n",
        "    # print(f\"Upvotes: {upvotes}\")\n",
        "    # print(f\"Number of Comments: {num_comments}\")\n",
        "    # print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
        "\n",
        "    # Ensures that the post is high quality and that there is content for models to read\n",
        "\n",
        "    # if (len(post_title) > 0 or len(post_content) > 0) and (int(upvotes) + int(num_comments)) > 1000 and len(data) < 1000:\n",
        "    #   data.append(dataStore(post_id, post_title, post_content, upvotes, num_comments))\n",
        "    # elif len(data) >= 1000:\n",
        "    #   break\n",
        "\n",
        "    # Unprocessed data\n",
        "    data.append(dataStore(post_id, post_title, post_content, upvotes, num_comments))\n",
        "    time.sleep(6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "\n",
        "# Convert the data to JSON\n",
        "jsonString = json.dumps(data, indent=2)\n",
        "\n",
        "# Load the JSON string back to a Python list\n",
        "convertedData = json.loads(jsonString)\n",
        "\n",
        "# Specify the CSV file name\n",
        "csv_file = 'data-query.csv'\n",
        "\n",
        "# Write the CSV file\n",
        "with open(csv_file, 'w', newline='') as csvfile:\n",
        "    # Extract the keys from the first dictionary to use as header\n",
        "    fieldnames = convertedData[0].keys()\n",
        "\n",
        "    # Create a CSV writer object\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    # Write the header\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Write the data\n",
        "    for row in convertedData:\n",
        "        writer.writerow(row)\n",
        "\n",
        "print(f'Conversion complete. CSV file saved as {csv_file}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBYESKjx4mxJ",
        "outputId": "4015e0f3-04b1-4d24-9fdd-5585b060f6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion complete. CSV file saved as output.csv\n"
          ]
        }
      ]
    }
  ]
}
