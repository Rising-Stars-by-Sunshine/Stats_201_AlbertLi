{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This file contains sample code to perform the data querying of the Reddit forum r/WallStreetBets."
      ],
      "metadata": {
        "id": "w9phcfZuAnEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install praw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymbUcBcxlH8J",
        "outputId": "5087c295-89f1-4b8f-8adc-0acbe06d0dd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.1 in /usr/local/lib/python3.10/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.6.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HaJ8LjwkYYj",
        "outputId": "5ef391bb-dfbe-4d8f-b13f-3ce014d5baec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Post ID: 1831zp9\n",
            "Title: Weekend Discussion Thread for the Weekend of November 25, 2023\n",
            "Content: # Come hang with us on [Discord](https://discord.gg/wsbverse)\n",
            "\n",
            "Check our [Earnings Thread](https://reddit.com/r/wallstreetbets/about/sticky?num=2) and [Rules](https://www.reddit.com/r/wallstreetbets/wiki/contentguide). DM the [mod inbox](https://www.reddit.com/message/compose/?to=/r/wallstreetbets)\n",
            "Upvotes: 48\n",
            "Number of Comments: 5290\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Post ID: 180z98f\n",
            "Title: Most Anticipated Earnings Releases for the week beginning November 27th, 2023\n",
            "Content: \n",
            "Upvotes: 96\n",
            "Number of Comments: 126\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Post ID: 18436lr\n",
            "Title: America Fuck Yea!!\n",
            "Content: \n",
            "Upvotes: 1884\n",
            "Number of Comments: 96\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Post ID: 183xqd0\n",
            "Title: My wifeâ€™s boyfriend just got her this sweater\n",
            "Content: \n",
            "Upvotes: 1444\n",
            "Number of Comments: 118\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Post ID: 183zako\n",
            "Title: Black Friday shoppers spent a record $9.8 billion in U.S. online sales, up 7.5% from last year\n",
            "Content: \n",
            "Upvotes: 1067\n",
            "Number of Comments: 278\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import praw\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set up PRAW with your Reddit API credentials\n",
        "reddit = praw.Reddit(\n",
        "    client_id= userdata.get('clientID'),\n",
        "    client_secret= userdata.get('clientSecret'),\n",
        "    user_agent= userdata.get('userAgent')\n",
        ")\n",
        "\n",
        "# Specify the subreddit you want to scrape\n",
        "subreddit_name = 'WallStreetBets'\n",
        "subreddit = reddit.subreddit(subreddit_name)\n",
        "\n",
        "# Iterate through the top 5 hot posts in the subreddit\n",
        "for submission in subreddit.hot(limit=5):\n",
        "    # Extract relevant information\n",
        "    post_id = submission.id\n",
        "    post_title = submission.title\n",
        "    post_content = submission.selftext,
        "    upvotes = submission.score\n",
        "    num_comments = submission.num_comments\n",
        "\n",
        "    # Print or store the information as needed\n",
        "    print(f\"Post ID: {post_id}\")\n",
        "    print(f\"Title: {post_title}\")\n",
        "    print(f\"Content: {post_content}\")\n",
        "    print(f\"Upvotes: {upvotes}\")\n",
        "    print(f\"Number of Comments: {num_comments}\")\n",
        "    print(\"\\n\" + \"-\" * 50 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "from data import *\n",
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import squarify\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "start_time = time.time()\n",
        "reddit = praw.Reddit(\n",
        "    user_agent=\"Comment Extraction\",\n",
        "    client_id=\"\",\n",
        "    client_secret=\"\"\n",
        ")\n",
        "\n",
        "'''############################################################################'''\n",
        "# set the program parameters\n",
        "subs = ['wallstreetbets', 'stocks', 'investing', 'stockmarket']     # sub-reddit to search\n",
        "post_flairs = {'Daily Discussion', 'Weekend Discussion', 'Discussion'}    # posts flairs to search || None flair is automatically considered\n",
        "goodAuth = {'AutoModerator'}   # authors whom comments are allowed more than once\n",
        "uniqueCmt = True                # allow one comment per author per symbol\n",
        "ignoreAuthP = {'example'}       # authors to ignore for posts\n",
        "ignoreAuthC = {'example'}       # authors to ignore for comment\n",
        "upvoteRatio = 0.70         # upvote ratio for post to be considered, 0.70 = 70%\n",
        "ups = 20       # define # of upvotes, post is considered if upvotes exceed this #\n",
        "limit = 10      # define the limit, comments 'replace more' limit\n",
        "upvotes = 2     # define # of upvotes, comment is considered if upvotes exceed this #\n",
        "picks = 10     # define # of picks here, prints as \"Top ## picks are:\"\n",
        "picks_ayz = 5   # define # of picks for sentiment analysis\n",
        "'''############################################################################'''\n",
        "\n",
        "posts, count, c_analyzed, tickers, titles, a_comments = 0, 0, 0, {}, [], {}\n",
        "cmt_auth = {}\n",
        "\n",
        "for sub in subs:\n",
        "    subreddit = reddit.subreddit(sub)\n",
        "    hot_python = subreddit.hot()    # sorting posts by hot\n",
        "\n",
        "\n",
        "# Extracting comments, symbols from subreddit\n",
        "    for submission in hot_python:\n",
        "        flair = submission.link_flair_text\n",
        "        author = submission.author.name"
      ],
      "metadata": {
        "id": "67ffisRwlm5p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
